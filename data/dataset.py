"""
æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æ¨¡å—
å¤„ç†ADE20Kæ ¼å¼çš„è¯­ä¹‰åˆ†å‰²æ•°æ®
"""
import os
import json
import cv2
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt


class ADE20KDataset(Dataset):
    """ADE20Kè¯­ä¹‰åˆ†å‰²æ•°æ®é›†"""
    
    def __init__(
        self,
        data_dir: str,
        target_classes: List[str],
        transform: Optional[A.Compose] = None,
        image_size: Tuple[int, int] = (256, 256),
        mode: str = "train",
        filter_empty_samples: bool = True
    ):
        self.data_dir = data_dir
        self.target_classes = target_classes
        self.transform = transform
        self.image_size = image_size
        self.split = "training" if mode == "train" else "validation"
        self.filter_empty_samples = filter_empty_samples
        self.samples = []
        
        # åˆ›å»ºç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„
        self.class_to_idx = {cls: idx for idx, cls in enumerate(target_classes)}
        
        self._load_samples()
    
    def _load_samples(self):
        """åŠ è½½æ‰€æœ‰æ ·æœ¬ - é€‚åº”ADE20Kæ ‡å‡†ç›®å½•ç»“æ„ï¼Œå¯é€‰æ‹©ç­›é€‰ç©ºæ ·æœ¬"""
        # ADE20Kæ ‡å‡†è·¯å¾„: ADE20K/images/ADE/training/
        ade_path = os.path.join(self.data_dir, "images", "ADE", self.split)
        
        if not os.path.exists(ade_path):
            print(f"è­¦å‘Š: è·¯å¾„ä¸å­˜åœ¨ {ade_path}")
            return
        
        all_samples = []
        valid_samples = []
        processed_count = 0
        
        print(f"ğŸ“‹ å¼€å§‹åŠ è½½ {self.split} æ•°æ®é›†...")
        
        # éå†æ‰€æœ‰åœºæ™¯ç±»åˆ«ç›®å½•
        for scene_type in os.listdir(ade_path):
            scene_path = os.path.join(ade_path, scene_type)
            if not os.path.isdir(scene_path):
                continue
                
            # éå†æ¯ä¸ªåœºæ™¯ä¸‹çš„å…·ä½“åœºæ™¯
            for scene_subdir in os.listdir(scene_path):
                scene_subdir_path = os.path.join(scene_path, scene_subdir)
                if not os.path.isdir(scene_subdir_path):
                    continue
                    
                # åŠ è½½è¯¥åœºæ™¯ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
                for file_name in os.listdir(scene_subdir_path):
                    if file_name.endswith('.jpg'):
                        base_name = file_name.replace('.jpg', '')
                        json_path = os.path.join(scene_subdir_path, f"{base_name}.json")
                        seg_path = os.path.join(scene_subdir_path, f"{base_name}_seg.png")
                        
                        if os.path.exists(json_path) and os.path.exists(seg_path):
                            sample = {
                                'image_path': os.path.join(scene_subdir_path, file_name),
                                'json_path': json_path,
                                'seg_path': seg_path,
                                'scene_class': scene_subdir,
                                'scene_type': scene_type
                            }
                            all_samples.append(sample)
                            
                            # å¦‚æœå¯ç”¨ç­›é€‰ï¼Œæ£€æŸ¥æ ·æœ¬æ˜¯å¦åŒ…å«ç›®æ ‡ç±»åˆ«
                            if self.filter_empty_samples:
                                if self._sample_has_target_classes(sample):
                                    valid_samples.append(sample)
                            else:
                                valid_samples.append(sample)
                            
                            processed_count += 1
                            if processed_count % 1000 == 0:
                                print(f"â³ å·²å¤„ç† {processed_count} ä¸ªæ ·æœ¬...")
        
        # æ ¹æ®ç­›é€‰è®¾ç½®é€‰æ‹©æœ€ç»ˆæ ·æœ¬
        self.samples = valid_samples
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        total_samples = len(all_samples)
        valid_samples_count = len(valid_samples)
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ:")
        print(f"  ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples:,}")
        if self.filter_empty_samples:
            filtered_count = total_samples - valid_samples_count
            filter_rate = (filtered_count / total_samples * 100) if total_samples > 0 else 0
            print(f"  ğŸ” ç­›é€‰åæ ·æœ¬æ•°: {valid_samples_count:,}")
            print(f"  ğŸ—‘ï¸  è¿‡æ»¤æ‰çš„ç©ºæ ·æœ¬: {filtered_count:,} ({filter_rate:.1f}%)")
        else:
            print(f"  ğŸ“ ä½¿ç”¨æ‰€æœ‰æ ·æœ¬: {valid_samples_count:,}")
    
    def _sample_has_target_classes(self, sample: dict) -> bool:
        """æ£€æŸ¥æ ·æœ¬æ˜¯å¦åŒ…å«ç›®æ ‡ç±»åˆ«"""
        try:
            # åŠ è½½æ ‡æ³¨æ–‡ä»¶
            annotation = self._load_annotation(sample['json_path'])
            objects = annotation.get('annotation', {}).get('object', [])
            
            # ä½¿ç”¨ä¸_create_maskç›¸åŒçš„æ˜ å°„é€»è¾‘
            ade20k_name_to_target = {
                # Personç±»åˆ«
                'person, individual, someone, somebody, mortal, soul': 'person',
                'person': 'person', 'individual': 'person', 'human': 'person',
                'man': 'person', 'woman': 'person', 'child': 'person', 'people': 'person',
                
                # Skyç±»åˆ«
                'sky': 'sky',
                
                # Treeç±»åˆ«
                'tree': 'tree', 'palm, palm tree': 'tree', 'palm tree': 'tree', 'palm': 'tree',
                
                # Rockç±»åˆ«
                'rock, stone': 'rock', 'rock': 'rock', 'stone': 'rock', 'stones': 'rock', 'boulder': 'rock',
                
                # Bushç±»åˆ«
                'shrub, bush': 'bush', 'bush': 'bush', 'shrub': 'bush', 'bushes': 'bush', 'ground shrubs': 'bush',
                
                # Grassç±»åˆ«
                'grass': 'grass', 'lawn': 'grass', 'turf': 'grass',
                
                # Dogç±»åˆ«
                'dog, domestic dog, canis familiaris': 'dog', 'dog': 'dog', 'dogs': 'dog', 'puppy': 'dog',
                
                # Catç±»åˆ«
                'cat': 'cat', 'cats': 'cat', 'kitten': 'cat',
                
                # Birdç±»åˆ«
                'bird': 'bird', 'birds': 'bird',
                
                # Duckç±»åˆ«
                'duck': 'duck', 'ducks': 'duck',
                
                # Cloudsç±»åˆ«
                'cloud': 'clouds', 'clouds': 'clouds',
                
                # Hillç±»åˆ«
                'hill': 'hill', 'hills': 'hill', 'mound': 'hill',
                
                # Leafç±»åˆ«
                'leaf, leafage, foliage': 'leaf', 'leaf': 'leaf', 'leaves': 'leaf', 'foliage': 'leaf',
                
                # Riverç±»åˆ«
                'river': 'river', 'stream': 'river', 'creek': 'river', 'brook': 'river',
                
                # Lakeç±»åˆ«
                'lake': 'lake', 'pond': 'lake', 'pond water': 'lake', 'reservoir': 'lake',
                
                # Flowerç±»åˆ«
                'flower': 'flower', 'flowers': 'flower', 'blossom': 'flower', 'bloom': 'flower', 'dried flowers': 'flower',
            }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•ç›®æ ‡ç±»åˆ«
            for obj in objects:
                obj_name = obj.get('name', '').strip()
                if not obj_name:
                    continue
                
                # ç›´æ¥æŸ¥æ‰¾ç²¾ç¡®åŒ¹é…
                target_class = ade20k_name_to_target.get(obj_name)
                
                # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•å°å†™åŒ¹é…
                if not target_class:
                    target_class = ade20k_name_to_target.get(obj_name.lower())
                
                if target_class and target_class in self.class_to_idx:
                    return True  # æ‰¾åˆ°è‡³å°‘ä¸€ä¸ªç›®æ ‡ç±»åˆ«
            
            return False  # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›®æ ‡ç±»åˆ«
            
        except Exception as e:
            # å¦‚æœå¤„ç†å¤±è´¥ï¼Œä¿å®ˆåœ°ä¿ç•™æ ·æœ¬
            return True
    
    def _load_annotation(self, json_path: str) -> Dict:
        """åŠ è½½æ ‡æ³¨æ–‡ä»¶"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except UnicodeDecodeError:
            try:
                # å°è¯•å…¶ä»–ç¼–ç 
                with open(json_path, 'r', encoding='latin-1') as f:
                    return json.load(f)
            except Exception:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè¿”å›ç©ºæ ‡æ³¨
                return {'annotation': {'object': []}}
    
    def _create_mask(self, annotation: Dict, seg_image: np.ndarray) -> np.ndarray:
        """æ ¹æ®æ ‡æ³¨åˆ›å»ºç›®æ ‡ç±»åˆ«çš„æ©ç  - é’ˆå¯¹ADE20Kå¤æ‚æ ‡æ³¨åç§°ä¼˜åŒ–"""
        h, w = seg_image.shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)

        # è·å–æ ‡æ³¨ä¸­çš„æ‰€æœ‰å¯¹è±¡
        objects = annotation.get('annotation', {}).get('object', [])

        # åŸºäºåˆ†æç»“æœåˆ›å»ºç²¾ç¡®çš„ADE20Kæ ‡æ³¨åç§°æ˜ å°„
        ade20k_name_to_target = {
            # Personç±»åˆ«
            'person, individual, someone, somebody, mortal, soul': 'person',
            'person': 'person',
            'individual': 'person',
            'human': 'person',
            'man': 'person',
            'woman': 'person',
            'child': 'person',
            'people': 'person',
            
            # Skyç±»åˆ«  
            'sky': 'sky',
            
            # Treeç±»åˆ«
            'tree': 'tree',
            'palm, palm tree': 'tree',
            'palm tree': 'tree',
            'palm': 'tree',
            
            # Rockç±»åˆ«
            'rock, stone': 'rock',
            'rock': 'rock',
            'stone': 'rock',
            'stones': 'rock',
            'boulder': 'rock',
            
            # Bushç±»åˆ«
            'shrub, bush': 'bush',
            'bush': 'bush',
            'shrub': 'bush',
            'bushes': 'bush',
            'ground shrubs': 'bush',
            
            # Grassç±»åˆ«
            'grass': 'grass',
            'lawn': 'grass',
            'turf': 'grass',
            
            # Dogç±»åˆ«
            'dog, domestic dog, canis familiaris': 'dog',
            'dog': 'dog',
            'dogs': 'dog',
            'puppy': 'dog',
            
            # Catç±»åˆ«
            'cat': 'cat',
            'cats': 'cat',
            'kitten': 'cat',
            
            # Birdç±»åˆ«
            'bird': 'bird',
            'birds': 'bird',
            
            # Duckç±»åˆ«
            'duck': 'duck',
            'ducks': 'duck',
            
            # Cloudsç±»åˆ«
            'cloud': 'clouds',
            'clouds': 'clouds',
            
            # Hillç±»åˆ«
            'hill': 'hill',
            'hills': 'hill',
            'mound': 'hill',
            
            # Leafç±»åˆ«
            'leaf, leafage, foliage': 'leaf',
            'leaf': 'leaf',
            'leaves': 'leaf',
            'foliage': 'leaf',
            
            # Riverç±»åˆ«
            'river': 'river',
            'stream': 'river',
            'creek': 'river',
            'brook': 'river',
            
            # Lakeç±»åˆ«
            'lake': 'lake',
            'pond': 'lake',
            'pond water': 'lake',
            'reservoir': 'lake',
            
            # Flowerç±»åˆ«
            'flower': 'flower',
            'flowers': 'flower',
            'blossom': 'flower',
            'bloom': 'flower',
            'dried flowers': 'flower',
        }

        for obj in objects:
            obj_name = obj.get('name', '').strip()
            if not obj_name:
                continue

            # ç›´æ¥æŸ¥æ‰¾ç²¾ç¡®åŒ¹é…
            target_class = ade20k_name_to_target.get(obj_name)
            
            # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•å°å†™åŒ¹é…
            if not target_class:
                target_class = ade20k_name_to_target.get(obj_name.lower())

            if target_class and target_class in self.class_to_idx:
                class_idx = self.class_to_idx[target_class]

                # è·å–å¤šè¾¹å½¢åæ ‡
                polygon = obj.get('polygon', {})
                if 'x' in polygon and 'y' in polygon:
                    x_coords = polygon['x']
                    y_coords = polygon['y']

                    if len(x_coords) == len(y_coords) and len(x_coords) >= 3:
                        # åˆ›å»ºå¤šè¾¹å½¢æ©ç 
                        points = np.array([[x, y] for x, y in zip(x_coords, y_coords)], dtype=np.int32)
                        cv2.fillPoly(mask, [points], class_idx)

        return mask
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(sample['image_path'])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # åŠ è½½åˆ†å‰²å›¾åƒï¼ˆç”¨äºè¾…åŠ©ï¼‰
        seg_image = cv2.imread(sample['seg_path'], cv2.IMREAD_GRAYSCALE)
        
        # åŠ è½½æ ‡æ³¨å¹¶åˆ›å»ºæ©ç 
        annotation = self._load_annotation(sample['json_path'])
        mask = self._create_mask(annotation, seg_image)
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            transformed = self.transform(image=image, mask=mask)
            image = transformed['image']
            mask = transformed['mask']
            # ç¡®ä¿æ©ç æ˜¯é•¿æ•´å‹
            mask = mask.long()
        else:
            # é»˜è®¤å˜æ¢
            image = cv2.resize(image, self.image_size)
            mask = cv2.resize(mask, self.image_size, interpolation=cv2.INTER_NEAREST)
            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0
            mask = torch.from_numpy(mask).long()
        
        return {
            'image': image,
            'mask': mask,
            'scene_class': sample['scene_class'],
            'image_path': sample['image_path']
        }


def get_transforms(image_size: Tuple[int, int] = (256, 256), mode: str = "train") -> A.Compose:
    """è·å–æ•°æ®å¢å¼ºå˜æ¢"""
    
    if mode == "train":
        return A.Compose([
            A.Resize(image_size[0], image_size[1]),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.2),
            A.RandomRotate90(p=0.3),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),
            A.GaussianBlur(blur_limit=(1, 3), p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], additional_targets={'mask': 'mask'})
    else:  # val/test
        return A.Compose([
            A.Resize(image_size[0], image_size[1]),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], additional_targets={'mask': 'mask'})


def create_dataloaders(
    data_dir: str,
    target_classes: List[str],
    batch_size: int = 8,
    image_size: Tuple[int, int] = (256, 256),
    train_ratio: float = 0.8,
    num_workers: int = 4
) -> Tuple[DataLoader, DataLoader]:
    """åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨"""
    
    # åˆ›å»ºæ•°æ®é›†
    full_dataset = ADE20KDataset(
        data_dir=data_dir,
        target_classes=target_classes,
        transform=None,  # æš‚æ—¶ä¸ç”¨å˜æ¢
        image_size=image_size
    )
    
    # åˆ’åˆ†è®­ç»ƒå’ŒéªŒè¯é›†
    total_size = len(full_dataset)
    train_size = int(total_size * train_ratio)
    val_size = total_size - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    # ä¸ºè®­ç»ƒå’ŒéªŒè¯é›†è®¾ç½®ä¸åŒçš„å˜æ¢
    train_dataset.dataset.transform = get_transforms(image_size, "train")
    val_dataset.dataset.transform = get_transforms(image_size, "val")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, val_loader


def visualize_sample(dataset: ADE20KDataset, idx: int = 0, save_path: Optional[str] = None):
    """å¯è§†åŒ–æ•°æ®é›†æ ·æœ¬"""
    sample = dataset[idx]
    
    image = sample['image']
    mask = sample['mask']
    
    # åå½’ä¸€åŒ–å›¾åƒ
    if image.max() <= 1.0:
        image = image * 255.0
    
    if len(image.shape) == 3 and image.shape[0] == 3:
        image = image.permute(1, 2, 0)
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # åŸå›¾
    axes[0].imshow(image.cpu().numpy().astype(np.uint8))
    axes[0].set_title("åŸå›¾")
    axes[0].axis('off')
    
    # æ©ç 
    axes[1].imshow(mask.cpu().numpy(), cmap='tab20')
    axes[1].set_title("åˆ†å‰²æ©ç ")
    axes[1].axis('off')
    
    # å åŠ å›¾
    overlay = image.cpu().numpy().astype(np.uint8).copy()
    mask_colored = plt.cm.tab20(mask.cpu().numpy() / len(dataset.target_classes))[:, :, :3]
    overlay = cv2.addWeighted(overlay, 0.7, (mask_colored * 255).astype(np.uint8), 0.3, 0)
    axes[2].imshow(overlay)
    axes[2].set_title("å åŠ å›¾")
    axes[2].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
    else:
        plt.show()


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†
    target_classes = [
        "clouds", "person", "sky", "hill", "rock", "tree", "leaf",
        "river", "lake", "bush", "dog", "cat", "flower", "grass", "bird", "duck"
    ]
    
    dataset = ADE20KDataset(
        data_dir="images",
        target_classes=target_classes,
        transform=get_transforms(mode="train")
    )
    
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"ç±»åˆ«æ˜ å°„: {dataset.class_to_idx}")
    
    if len(dataset) > 0:
        sample = dataset[0]
        print(f"æ ·æœ¬é”®: {sample.keys()}")
        print(f"å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        print(f"æ©ç å½¢çŠ¶: {sample['mask'].shape}")
        print(f"æ©ç å”¯ä¸€å€¼: {torch.unique(sample['mask'])}")
