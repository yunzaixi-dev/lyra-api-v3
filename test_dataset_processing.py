#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„æ•°æ®é›†å¤„ç†é€»è¾‘
éªŒè¯å„ä¸ªç±»åˆ«çš„æ ‡æ³¨æ˜¯å¦æ­£ç¡®
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from data.dataset import ADE20KDataset, get_transforms

# ç›®æ ‡ç±»åˆ«
TARGET_CLASSES = [
    'background', 'clouds', 'person', 'sky', 'hill', 'rock', 'tree', 
    'leaf', 'river', 'lake', 'bush', 'dog', 'cat', 'flower', 'grass', 
    'bird', 'duck'
]

def test_dataset_processing(data_dir: str = "ADE20K", num_samples: int = 50):
    """æµ‹è¯•æ•°æ®é›†å¤„ç†é€»è¾‘"""
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä¿®å¤åçš„æ•°æ®é›†å¤„ç†é€»è¾‘...")
    
    # åˆ›å»ºæ•°æ®é›†å®ä¾‹
    dataset = ADE20KDataset(
        data_dir=data_dir,
        target_classes=TARGET_CLASSES,
        transform=None,  # ä¸ä½¿ç”¨å˜æ¢ï¼Œæ–¹ä¾¿æŸ¥çœ‹åŸå§‹ç»“æœ
        image_size=(256, 256),
        mode="train"
    )
    
    if len(dataset) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
        return
    
    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"ğŸ¯ ç›®æ ‡ç±»åˆ«æ•°: {len(TARGET_CLASSES)}")
    
    # ç»Ÿè®¡å„ç±»åˆ«åœ¨æ©ç ä¸­çš„å‡ºç°æƒ…å†µ
    class_pixel_counts = Counter()
    class_occurrence_counts = Counter()
    total_samples_tested = 0
    
    # æµ‹è¯•æŒ‡å®šæ•°é‡çš„æ ·æœ¬
    test_samples = min(num_samples, len(dataset))
    print(f"ğŸ“‹ æµ‹è¯•æ ·æœ¬æ•°: {test_samples}")
    
    for i in range(test_samples):
        try:
            sample = dataset[i]
            mask = sample['mask']
            
            # ç»Ÿè®¡è¯¥æ ·æœ¬ä¸­æ¯ä¸ªç±»åˆ«çš„åƒç´ æ•°
            unique_classes, counts = torch.unique(mask, return_counts=True)
            
            for class_idx, count in zip(unique_classes, counts):
                class_idx = class_idx.item()
                count = count.item()
                
                if class_idx < len(TARGET_CLASSES):
                    class_name = TARGET_CLASSES[class_idx]
                    class_pixel_counts[class_name] += count
                    
                    # å¦‚æœè¯¥ç±»åˆ«åœ¨æ­¤æ ·æœ¬ä¸­å‡ºç°ï¼Œè®°å½•ä¸€æ¬¡
                    if count > 0 and class_idx > 0:  # å¿½ç•¥èƒŒæ™¯ç±»
                        class_occurrence_counts[class_name] += 1
            
            total_samples_tested += 1
            
            if (i + 1) % 10 == 0:
                print(f"â³ å·²æµ‹è¯• {i + 1}/{test_samples} ä¸ªæ ·æœ¬...")
                
        except Exception as e:
            print(f"âš ï¸ æ ·æœ¬ {i} å¤„ç†å¤±è´¥: {e}")
            continue
    
    print(f"âœ… æµ‹è¯•å®Œæˆï¼æˆåŠŸå¤„ç† {total_samples_tested} ä¸ªæ ·æœ¬")
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print_test_results(class_pixel_counts, class_occurrence_counts, total_samples_tested)
    
    # åˆ›å»ºå¯è§†åŒ–æ ·æœ¬
    create_sample_visualizations(dataset, num_vis_samples=5)
    
    return class_pixel_counts, class_occurrence_counts

def print_test_results(pixel_counts: Counter, occurrence_counts: Counter, total_samples: int):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    
    print(f"\nğŸ“ˆ ç±»åˆ«æ£€æµ‹ç»Ÿè®¡ç»“æœ:")
    print(f"{'ç±»åˆ«åç§°':<12} {'æ ·æœ¬æ•°':<8} {'åƒç´ æ€»æ•°':<12} {'å¹³å‡åƒç´ ':<10} {'æ£€æµ‹ç‡':<8}")
    print("-" * 60)
    
    zero_detection_classes = []
    
    for class_name in TARGET_CLASSES[1:]:  # è·³è¿‡background
        sample_count = occurrence_counts.get(class_name, 0)
        pixel_count = pixel_counts.get(class_name, 0)
        avg_pixels = pixel_count / max(sample_count, 1)
        detection_rate = (sample_count / total_samples) * 100
        
        print(f"{class_name:<12} {sample_count:<8} {pixel_count:<12,} {avg_pixels:<10.1f} {detection_rate:<8.1f}%")
        
        if sample_count == 0:
            zero_detection_classes.append(class_name)
    
    # åˆ†æç»“æœ
    print(f"\nğŸ¯ æ£€æµ‹åˆ†æ:")
    if zero_detection_classes:
        print(f"  âŒ æœªæ£€æµ‹åˆ°çš„ç±»åˆ« ({len(zero_detection_classes)}ä¸ª): {', '.join(zero_detection_classes)}")
    else:
        print(f"  âœ… æ‰€æœ‰ç›®æ ‡ç±»åˆ«éƒ½è¢«æ£€æµ‹åˆ°ï¼")
    
    detected_classes = len(TARGET_CLASSES) - 1 - len(zero_detection_classes)
    print(f"  ğŸ“Š æ£€æµ‹æˆåŠŸç‡: {detected_classes}/{len(TARGET_CLASSES)-1} ({(detected_classes/(len(TARGET_CLASSES)-1)*100):.1f}%)")
    
    # æ£€æµ‹é¢‘ç‡æœ€é«˜çš„ç±»åˆ«
    print(f"\nğŸ” æ£€æµ‹é¢‘ç‡æœ€é«˜çš„5ä¸ªç±»åˆ«:")
    for class_name, count in occurrence_counts.most_common(5):
        rate = (count / total_samples) * 100
        print(f"  {class_name}: {count}æ¬¡ ({rate:.1f}%)")

def create_sample_visualizations(dataset: ADE20KDataset, num_vis_samples: int = 5):
    """åˆ›å»ºæ ·æœ¬å¯è§†åŒ–"""
    
    print(f"\nğŸ–¼ï¸ åˆ›å»º {num_vis_samples} ä¸ªæ ·æœ¬çš„å¯è§†åŒ–...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("outputs", exist_ok=True)
    
    # é€‰æ‹©æœ‰å¤šä¸ªç±»åˆ«çš„æ ·æœ¬è¿›è¡Œå¯è§†åŒ–
    selected_samples = []
    for i in range(min(len(dataset), 100)):  # æ£€æŸ¥å‰100ä¸ªæ ·æœ¬
        try:
            sample = dataset[i]
            mask = sample['mask']
            unique_classes = torch.unique(mask)
            
            # é€‰æ‹©åŒ…å«å¤šä¸ªç±»åˆ«çš„æ ·æœ¬ï¼ˆä¸ä»…ä»…æ˜¯èƒŒæ™¯ï¼‰
            if len(unique_classes) >= 3:  # è‡³å°‘3ä¸ªç±»åˆ«ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰
                selected_samples.append(i)
                if len(selected_samples) >= num_vis_samples:
                    break
        except:
            continue
    
    if not selected_samples:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ…å«å¤šä¸ªç±»åˆ«çš„æ ·æœ¬")
        return
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(num_vis_samples, 3, figsize=(15, 5 * num_vis_samples))
    if num_vis_samples == 1:
        axes = [axes]
    
    for idx, sample_idx in enumerate(selected_samples):
        try:
            sample = dataset[sample_idx]
            image = sample['image']
            mask = sample['mask']
            
            # è½¬æ¢å›¾åƒæ ¼å¼ç”¨äºæ˜¾ç¤º
            if isinstance(image, torch.Tensor):
                if image.max() <= 1.0:
                    image = (image * 255).clamp(0, 255)
                if image.shape[0] == 3:  # CHWæ ¼å¼
                    image = image.permute(1, 2, 0)
                image = image.numpy().astype(np.uint8)
            
            # åŸå›¾
            axes[idx][0].imshow(image)
            axes[idx][0].set_title(f'åŸå›¾ - æ ·æœ¬ {sample_idx}')
            axes[idx][0].axis('off')
            
            # æ©ç 
            mask_np = mask.numpy() if isinstance(mask, torch.Tensor) else mask
            im = axes[idx][1].imshow(mask_np, cmap='tab20', vmin=0, vmax=len(TARGET_CLASSES)-1)
            axes[idx][1].set_title('åˆ†å‰²æ©ç ')
            axes[idx][1].axis('off')
            
            # å åŠ å›¾
            colored_mask = plt.cm.tab20(mask_np / len(TARGET_CLASSES))[:, :, :3]
            overlay = image.astype(float) * 0.6 + colored_mask * 255 * 0.4
            overlay = np.clip(overlay, 0, 255).astype(np.uint8)
            axes[idx][2].imshow(overlay)
            axes[idx][2].set_title('å åŠ æ•ˆæœ')
            axes[idx][2].axis('off')
            
            # æ˜¾ç¤ºè¯¥æ ·æœ¬ä¸­åŒ…å«çš„ç±»åˆ«
            unique_classes = np.unique(mask_np)
            class_names = [TARGET_CLASSES[i] for i in unique_classes if i < len(TARGET_CLASSES)]
            print(f"  æ ·æœ¬ {sample_idx} åŒ…å«ç±»åˆ«: {', '.join(class_names)}")
            
        except Exception as e:
            print(f"âš ï¸ æ ·æœ¬ {sample_idx} å¯è§†åŒ–å¤±è´¥: {e}")
    
    plt.tight_layout()
    save_path = "outputs/dataset_test_samples.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“¸ æ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†å¤„ç†
    pixel_counts, occurrence_counts = test_dataset_processing(num_samples=50)
    
    print(f"\nğŸ’¡ æµ‹è¯•æ€»ç»“:")
    print(f"  ä¿®å¤åçš„æ•°æ®å¤„ç†é€»è¾‘å·²ç”Ÿæ•ˆ")
    print(f"  å»ºè®®æ£€æŸ¥å¯è§†åŒ–ç»“æœç¡®è®¤ç±»åˆ«æ ‡æ³¨çš„å‡†ç¡®æ€§")
    print(f"  å¦‚æœæ‰€æœ‰ç›®æ ‡ç±»åˆ«éƒ½èƒ½è¢«æ£€æµ‹åˆ°ï¼Œå¯ä»¥å¼€å§‹é‡æ–°è®­ç»ƒ")
